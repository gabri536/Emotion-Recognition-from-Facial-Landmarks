{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550e61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a13a7",
   "metadata": {},
   "source": [
    "We have created a df, that stores all the image paths and is sorted by label and split.\n",
    "We first want to load that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238b5868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FER-2013\\test\\angry\\PrivateTest_10131363.jpg</td>\n",
       "      <td>angry</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FER-2013\\test\\angry\\PrivateTest_10304478.jpg</td>\n",
       "      <td>angry</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FER-2013\\test\\angry\\PrivateTest_1054527.jpg</td>\n",
       "      <td>angry</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FER-2013\\test\\angry\\PrivateTest_10590091.jpg</td>\n",
       "      <td>angry</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FER-2013\\test\\angry\\PrivateTest_1109992.jpg</td>\n",
       "      <td>angry</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>FER-2013\\test\\surprise\\PublicTest_98089595.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>FER-2013\\test\\surprise\\PublicTest_98567249.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>FER-2013\\test\\surprise\\PublicTest_98972870.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>FER-2013\\test\\surprise\\PublicTest_99242645.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>FER-2013\\test\\surprise\\PublicTest_99446963.jpg</td>\n",
       "      <td>surprise</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath     label split\n",
       "0       FER-2013\\test\\angry\\PrivateTest_10131363.jpg     angry  test\n",
       "1       FER-2013\\test\\angry\\PrivateTest_10304478.jpg     angry  test\n",
       "2        FER-2013\\test\\angry\\PrivateTest_1054527.jpg     angry  test\n",
       "3       FER-2013\\test\\angry\\PrivateTest_10590091.jpg     angry  test\n",
       "4        FER-2013\\test\\angry\\PrivateTest_1109992.jpg     angry  test\n",
       "...                                              ...       ...   ...\n",
       "7173  FER-2013\\test\\surprise\\PublicTest_98089595.jpg  surprise  test\n",
       "7174  FER-2013\\test\\surprise\\PublicTest_98567249.jpg  surprise  test\n",
       "7175  FER-2013\\test\\surprise\\PublicTest_98972870.jpg  surprise  test\n",
       "7176  FER-2013\\test\\surprise\\PublicTest_99242645.jpg  surprise  test\n",
       "7177  FER-2013\\test\\surprise\\PublicTest_99446963.jpg  surprise  test\n",
       "\n",
       "[7178 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train/fer2013_train.csv')\n",
    "test_df  = pd.read_csv('data/test/fer2013_test.csv')\n",
    "\n",
    "train_df\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e1ee4",
   "metadata": {},
   "source": [
    "It is good practice to add a third validation split when working with machine learning libraries. So that in the end when testing the model you get a totally unbiased test accuarcy. The validation split is used to finetune hyperparameters. It is ussually computed after each epoch. So first we will split our test data into test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83ea4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24085      sad\n",
      "7006      fear\n",
      "20924      sad\n",
      "7514      fear\n",
      "11       angry\n",
      "         ...  \n",
      "8174      fear\n",
      "3952     angry\n",
      "11548    happy\n",
      "13290    happy\n",
      "23832      sad\n",
      "Name: label, Length: 25838, dtype: object\n",
      "26775    surprise\n",
      "3507        angry\n",
      "26872    surprise\n",
      "13601       happy\n",
      "15976     neutral\n",
      "           ...   \n",
      "14927       happy\n",
      "17773     neutral\n",
      "160         angry\n",
      "24621         sad\n",
      "4761         fear\n",
      "Name: label, Length: 2871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# stratify to keep the same class balance\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_df['filepath'], train_df['label'],\n",
    "    test_size=0.1,  # e.g. 10% of training for validation\n",
    "    stratify=train_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "print(train_labels)\n",
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61743f",
   "metadata": {},
   "source": [
    "Next we want to encode our labels numerically. We will use the integers 0, ..., 6 and in the end use the softmax activation function to let the modell decide which class is the most likely. COntrary two the two options we learned in the course being one against one, or one against all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7392b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# labels nummern hinzufügen, also welche ziffer welchem label entspricht\n",
    "le = LabelEncoder().fit(train_labels)\n",
    "train_y_int = le.transform(train_labels)           # ints 0…6\n",
    "val_y_int   = le.transform(val_labels) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f653bf",
   "metadata": {},
   "source": [
    "We will define a function that can read the iamges and format them into a 48*48*1 matrix with the last dimension being used for the label and 48*48 representing the picture in grayscale format. If we would have a color picture we could format it into 48*48*3*1 the third dimension being used for encoding blue green and red pixel values. It is also custom and good practice to normalite the pixel values to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cde3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess(path, target_size=(48,48)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)      # FER-2013 is grayscale\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0               # normalize to [0,1]\n",
    "    return np.expand_dims(img, axis=-1)               # shape (48,48,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82a313d",
   "metadata": {},
   "source": [
    "Next we want to prepare the dataset on which our training happens. tensorflow uses enables you to use so called generator function to allow us to create the nmerical matrices we talked about before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52252ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_21372\\3059112169.py:8: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_21372\\3059112169.py:8: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "Image batch shape: (64, 48, 48, 1)\n",
      "Label batch shape: (64,)\n",
      "Label values: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def gen(paths, labels):\n",
    "    for p, l in zip(paths, labels):\n",
    "        img = load_and_preprocess(p)\n",
    "        yield img, l\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: gen(train_paths, train_y_int),\n",
    "    output_types=(tf.float32, tf.int32),\n",
    "    output_shapes=([48,48,1], [])\n",
    ")\n",
    "train_ds = (train_ds\n",
    "            .shuffle(1000)\n",
    "            .batch(64)\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "val_ds = (tf.data.Dataset.from_generator(\n",
    "            lambda: gen(val_paths,   val_y_int),\n",
    "            output_types=(tf.float32, tf.int32),\n",
    "            output_shapes=([48,48,1], [])\n",
    "          )\n",
    "          .batch(64)\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "#generator functions erklären ein bisschen auf tf.dataset eingehen\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)   # e.g. (64,48,48,1)\n",
    "    print(\"Label batch shape:\", labels.shape)   # e.g. (64,)\n",
    "    print(\"Label values:\", np.unique(labels.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884376f",
   "metadata": {},
   "source": [
    "Lastly we want to build our model. First we will just use a basic CNN model with only one convolutional layer and a pooling layer. The convolutional layer is mostly used to extract features from the pictures. We want to see if these features are already linearly seperable and if the model can achieve good performance without an additional fully connected layer. We will also build a normal cnn model that has an addiotional fully connected layer after the convolutional layer and test the perfomances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99da016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18432</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">129,031</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18432\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │       \u001b[38;5;34m129,031\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,351</span> (505.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m129,351\u001b[0m (505.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,351</span> (505.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,351\u001b[0m (505.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\anaconda3\\envs\\applied_ml\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 - 459s - 1s/step - accuracy: 0.3517 - loss: 1.6530 - val_accuracy: 0.4194 - val_loss: 1.5546\n",
      "Epoch 2/100\n",
      "404/404 - 33s - 82ms/step - accuracy: 0.4354 - loss: 1.4900 - val_accuracy: 0.4155 - val_loss: 1.5121\n",
      "Epoch 3/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.4701 - loss: 1.4136 - val_accuracy: 0.4521 - val_loss: 1.4669\n",
      "Epoch 4/100\n",
      "404/404 - 32s - 78ms/step - accuracy: 0.4913 - loss: 1.3568 - val_accuracy: 0.4455 - val_loss: 1.4760\n",
      "Epoch 5/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.5130 - loss: 1.3071 - val_accuracy: 0.4573 - val_loss: 1.4615\n",
      "Epoch 6/100\n",
      "404/404 - 34s - 85ms/step - accuracy: 0.5309 - loss: 1.2651 - val_accuracy: 0.4615 - val_loss: 1.4468\n",
      "Epoch 7/100\n",
      "404/404 - 32s - 79ms/step - accuracy: 0.5475 - loss: 1.2264 - val_accuracy: 0.4653 - val_loss: 1.4447\n",
      "Epoch 8/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.5626 - loss: 1.1954 - val_accuracy: 0.4525 - val_loss: 1.4937\n",
      "Epoch 9/100\n",
      "404/404 - 33s - 81ms/step - accuracy: 0.5740 - loss: 1.1626 - val_accuracy: 0.4657 - val_loss: 1.4702\n",
      "Epoch 10/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.5840 - loss: 1.1317 - val_accuracy: 0.4688 - val_loss: 1.4628\n",
      "Epoch 11/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.5971 - loss: 1.1048 - val_accuracy: 0.4559 - val_loss: 1.4782\n",
      "Epoch 12/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.6065 - loss: 1.0769 - val_accuracy: 0.4674 - val_loss: 1.5022\n",
      "Epoch 13/100\n",
      "404/404 - 33s - 83ms/step - accuracy: 0.6180 - loss: 1.0482 - val_accuracy: 0.4594 - val_loss: 1.5336\n",
      "Epoch 14/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.6297 - loss: 1.0246 - val_accuracy: 0.4507 - val_loss: 1.5129\n",
      "Epoch 15/100\n",
      "404/404 - 34s - 85ms/step - accuracy: 0.6426 - loss: 0.9950 - val_accuracy: 0.4629 - val_loss: 1.5213\n",
      "Epoch 16/100\n",
      "404/404 - 32s - 80ms/step - accuracy: 0.6518 - loss: 0.9709 - val_accuracy: 0.4629 - val_loss: 1.5080\n",
      "Epoch 17/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.6586 - loss: 0.9517 - val_accuracy: 0.4525 - val_loss: 1.5661\n",
      "Epoch 18/100\n",
      "404/404 - 32s - 80ms/step - accuracy: 0.6696 - loss: 0.9243 - val_accuracy: 0.4660 - val_loss: 1.5625\n",
      "Epoch 19/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.6791 - loss: 0.9029 - val_accuracy: 0.4685 - val_loss: 1.5946\n",
      "Epoch 20/100\n",
      "404/404 - 33s - 82ms/step - accuracy: 0.6859 - loss: 0.8815 - val_accuracy: 0.4674 - val_loss: 1.5708\n",
      "Epoch 21/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.6972 - loss: 0.8580 - val_accuracy: 0.4737 - val_loss: 1.5751\n",
      "Epoch 22/100\n",
      "404/404 - 35s - 85ms/step - accuracy: 0.7054 - loss: 0.8381 - val_accuracy: 0.4639 - val_loss: 1.6001\n",
      "Epoch 23/100\n",
      "404/404 - 32s - 79ms/step - accuracy: 0.7125 - loss: 0.8176 - val_accuracy: 0.4514 - val_loss: 1.6630\n",
      "Epoch 24/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.7218 - loss: 0.7972 - val_accuracy: 0.4479 - val_loss: 1.6465\n",
      "Epoch 25/100\n",
      "404/404 - 33s - 81ms/step - accuracy: 0.7306 - loss: 0.7752 - val_accuracy: 0.4664 - val_loss: 1.6485\n",
      "Epoch 26/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.7359 - loss: 0.7593 - val_accuracy: 0.4660 - val_loss: 1.6931\n",
      "Epoch 27/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.7457 - loss: 0.7377 - val_accuracy: 0.4653 - val_loss: 1.7026\n",
      "Epoch 28/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.7544 - loss: 0.7214 - val_accuracy: 0.4702 - val_loss: 1.7107\n",
      "Epoch 29/100\n",
      "404/404 - 34s - 85ms/step - accuracy: 0.7603 - loss: 0.7056 - val_accuracy: 0.4657 - val_loss: 1.7327\n",
      "Epoch 30/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.7679 - loss: 0.6860 - val_accuracy: 0.4528 - val_loss: 1.7484\n",
      "Epoch 31/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.7742 - loss: 0.6706 - val_accuracy: 0.4622 - val_loss: 1.7728\n",
      "Epoch 32/100\n",
      "404/404 - 37s - 92ms/step - accuracy: 0.7819 - loss: 0.6520 - val_accuracy: 0.4657 - val_loss: 1.7574\n",
      "Epoch 33/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.7856 - loss: 0.6377 - val_accuracy: 0.4633 - val_loss: 1.8106\n",
      "Epoch 34/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.7913 - loss: 0.6237 - val_accuracy: 0.4552 - val_loss: 1.8398\n",
      "Epoch 35/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.7982 - loss: 0.6116 - val_accuracy: 0.4629 - val_loss: 1.8728\n",
      "Epoch 36/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.8072 - loss: 0.5910 - val_accuracy: 0.4619 - val_loss: 1.8612\n",
      "Epoch 37/100\n",
      "404/404 - 34s - 85ms/step - accuracy: 0.8089 - loss: 0.5789 - val_accuracy: 0.4598 - val_loss: 1.9009\n",
      "Epoch 38/100\n",
      "404/404 - 37s - 92ms/step - accuracy: 0.8140 - loss: 0.5671 - val_accuracy: 0.4601 - val_loss: 1.8791\n",
      "Epoch 39/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.8234 - loss: 0.5509 - val_accuracy: 0.4636 - val_loss: 1.9060\n",
      "Epoch 40/100\n",
      "404/404 - 37s - 92ms/step - accuracy: 0.8286 - loss: 0.5375 - val_accuracy: 0.4626 - val_loss: 1.9583\n",
      "Epoch 41/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.8333 - loss: 0.5221 - val_accuracy: 0.4577 - val_loss: 1.9642\n",
      "Epoch 42/100\n",
      "404/404 - 38s - 94ms/step - accuracy: 0.8355 - loss: 0.5148 - val_accuracy: 0.4577 - val_loss: 2.0279\n",
      "Epoch 43/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.8400 - loss: 0.5035 - val_accuracy: 0.4563 - val_loss: 1.9933\n",
      "Epoch 44/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.8467 - loss: 0.4870 - val_accuracy: 0.4577 - val_loss: 2.0245\n",
      "Epoch 45/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.8508 - loss: 0.4751 - val_accuracy: 0.4437 - val_loss: 2.0720\n",
      "Epoch 46/100\n",
      "404/404 - 33s - 83ms/step - accuracy: 0.8592 - loss: 0.4607 - val_accuracy: 0.4552 - val_loss: 2.0692\n",
      "Epoch 47/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.8573 - loss: 0.4556 - val_accuracy: 0.4566 - val_loss: 2.1059\n",
      "Epoch 48/100\n",
      "404/404 - 33s - 82ms/step - accuracy: 0.8631 - loss: 0.4440 - val_accuracy: 0.4549 - val_loss: 2.1058\n",
      "Epoch 49/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.8699 - loss: 0.4283 - val_accuracy: 0.4521 - val_loss: 2.1528\n",
      "Epoch 50/100\n",
      "404/404 - 32s - 80ms/step - accuracy: 0.8740 - loss: 0.4200 - val_accuracy: 0.4500 - val_loss: 2.1702\n",
      "Epoch 51/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.8781 - loss: 0.4084 - val_accuracy: 0.4483 - val_loss: 2.2135\n",
      "Epoch 52/100\n",
      "404/404 - 39s - 96ms/step - accuracy: 0.8827 - loss: 0.4012 - val_accuracy: 0.4490 - val_loss: 2.2167\n",
      "Epoch 53/100\n",
      "404/404 - 231s - 572ms/step - accuracy: 0.8832 - loss: 0.3933 - val_accuracy: 0.4507 - val_loss: 2.2905\n",
      "Epoch 54/100\n",
      "404/404 - 78s - 194ms/step - accuracy: 0.8860 - loss: 0.3842 - val_accuracy: 0.4427 - val_loss: 2.2934\n",
      "Epoch 55/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.8931 - loss: 0.3726 - val_accuracy: 0.4375 - val_loss: 2.3033\n",
      "Epoch 56/100\n",
      "404/404 - 38s - 94ms/step - accuracy: 0.8973 - loss: 0.3623 - val_accuracy: 0.4451 - val_loss: 2.3149\n",
      "Epoch 57/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.8999 - loss: 0.3546 - val_accuracy: 0.4458 - val_loss: 2.3432\n",
      "Epoch 58/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9033 - loss: 0.3452 - val_accuracy: 0.4469 - val_loss: 2.4026\n",
      "Epoch 59/100\n",
      "404/404 - 37s - 92ms/step - accuracy: 0.9083 - loss: 0.3362 - val_accuracy: 0.4448 - val_loss: 2.3966\n",
      "Epoch 60/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9088 - loss: 0.3312 - val_accuracy: 0.4497 - val_loss: 2.4561\n",
      "Epoch 61/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.9098 - loss: 0.3249 - val_accuracy: 0.4441 - val_loss: 2.4965\n",
      "Epoch 62/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.9184 - loss: 0.3096 - val_accuracy: 0.4486 - val_loss: 2.4803\n",
      "Epoch 63/100\n",
      "404/404 - 37s - 90ms/step - accuracy: 0.9189 - loss: 0.3028 - val_accuracy: 0.4542 - val_loss: 2.5108\n",
      "Epoch 64/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.9215 - loss: 0.2988 - val_accuracy: 0.4483 - val_loss: 2.5392\n",
      "Epoch 65/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.9228 - loss: 0.2933 - val_accuracy: 0.4493 - val_loss: 2.5679\n",
      "Epoch 66/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.9271 - loss: 0.2820 - val_accuracy: 0.4538 - val_loss: 2.6211\n",
      "Epoch 67/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9315 - loss: 0.2723 - val_accuracy: 0.4518 - val_loss: 2.6364\n",
      "Epoch 68/100\n",
      "404/404 - 32s - 78ms/step - accuracy: 0.9343 - loss: 0.2675 - val_accuracy: 0.4441 - val_loss: 2.6478\n",
      "Epoch 69/100\n",
      "404/404 - 29s - 71ms/step - accuracy: 0.9338 - loss: 0.2650 - val_accuracy: 0.4389 - val_loss: 2.6942\n",
      "Epoch 70/100\n",
      "404/404 - 28s - 70ms/step - accuracy: 0.9349 - loss: 0.2588 - val_accuracy: 0.4434 - val_loss: 2.7046\n",
      "Epoch 71/100\n",
      "404/404 - 28s - 70ms/step - accuracy: 0.9395 - loss: 0.2487 - val_accuracy: 0.4455 - val_loss: 2.7480\n",
      "Epoch 72/100\n",
      "404/404 - 29s - 71ms/step - accuracy: 0.9437 - loss: 0.2418 - val_accuracy: 0.4451 - val_loss: 2.8144\n",
      "Epoch 73/100\n",
      "404/404 - 27s - 68ms/step - accuracy: 0.9443 - loss: 0.2365 - val_accuracy: 0.4316 - val_loss: 2.8389\n",
      "Epoch 74/100\n",
      "404/404 - 28s - 69ms/step - accuracy: 0.9465 - loss: 0.2313 - val_accuracy: 0.4396 - val_loss: 2.8315\n",
      "Epoch 75/100\n",
      "404/404 - 28s - 70ms/step - accuracy: 0.9501 - loss: 0.2246 - val_accuracy: 0.4444 - val_loss: 2.8474\n",
      "Epoch 76/100\n",
      "404/404 - 29s - 71ms/step - accuracy: 0.9486 - loss: 0.2217 - val_accuracy: 0.4343 - val_loss: 2.9066\n",
      "Epoch 77/100\n",
      "404/404 - 29s - 72ms/step - accuracy: 0.9532 - loss: 0.2137 - val_accuracy: 0.4382 - val_loss: 2.9154\n",
      "Epoch 78/100\n",
      "404/404 - 27s - 67ms/step - accuracy: 0.9551 - loss: 0.2062 - val_accuracy: 0.4431 - val_loss: 2.9524\n",
      "Epoch 79/100\n",
      "404/404 - 30s - 75ms/step - accuracy: 0.9546 - loss: 0.2064 - val_accuracy: 0.4434 - val_loss: 3.0194\n",
      "Epoch 80/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9600 - loss: 0.1964 - val_accuracy: 0.4462 - val_loss: 3.0139\n",
      "Epoch 81/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.9581 - loss: 0.1966 - val_accuracy: 0.4476 - val_loss: 3.1101\n",
      "Epoch 82/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.9599 - loss: 0.1910 - val_accuracy: 0.4382 - val_loss: 3.0981\n",
      "Epoch 83/100\n",
      "404/404 - 33s - 82ms/step - accuracy: 0.9635 - loss: 0.1831 - val_accuracy: 0.4448 - val_loss: 3.1136\n",
      "Epoch 84/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9654 - loss: 0.1791 - val_accuracy: 0.4434 - val_loss: 3.1301\n",
      "Epoch 85/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9673 - loss: 0.1732 - val_accuracy: 0.4458 - val_loss: 3.1531\n",
      "Epoch 86/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9673 - loss: 0.1727 - val_accuracy: 0.4385 - val_loss: 3.2208\n",
      "Epoch 87/100\n",
      "404/404 - 34s - 83ms/step - accuracy: 0.9658 - loss: 0.1708 - val_accuracy: 0.4448 - val_loss: 3.2299\n",
      "Epoch 88/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9692 - loss: 0.1631 - val_accuracy: 0.4375 - val_loss: 3.2743\n",
      "Epoch 89/100\n",
      "404/404 - 34s - 84ms/step - accuracy: 0.9736 - loss: 0.1540 - val_accuracy: 0.4371 - val_loss: 3.2812\n",
      "Epoch 90/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9735 - loss: 0.1527 - val_accuracy: 0.4427 - val_loss: 3.3358\n",
      "Epoch 91/100\n",
      "404/404 - 37s - 93ms/step - accuracy: 0.9736 - loss: 0.1504 - val_accuracy: 0.4424 - val_loss: 3.3642\n",
      "Epoch 92/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9770 - loss: 0.1469 - val_accuracy: 0.4399 - val_loss: 3.3884\n",
      "Epoch 93/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9759 - loss: 0.1433 - val_accuracy: 0.4364 - val_loss: 3.4264\n",
      "Epoch 94/100\n",
      "404/404 - 38s - 94ms/step - accuracy: 0.9767 - loss: 0.1380 - val_accuracy: 0.4357 - val_loss: 3.4562\n",
      "Epoch 95/100\n",
      "404/404 - 34s - 83ms/step - accuracy: 0.9775 - loss: 0.1352 - val_accuracy: 0.4371 - val_loss: 3.4741\n",
      "Epoch 96/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.9797 - loss: 0.1330 - val_accuracy: 0.4399 - val_loss: 3.5057\n",
      "Epoch 97/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.9802 - loss: 0.1290 - val_accuracy: 0.4364 - val_loss: 3.5545\n",
      "Epoch 98/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9798 - loss: 0.1294 - val_accuracy: 0.4431 - val_loss: 3.5885\n",
      "Epoch 99/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9806 - loss: 0.1241 - val_accuracy: 0.4347 - val_loss: 3.6160\n",
      "Epoch 100/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9816 - loss: 0.1218 - val_accuracy: 0.4396 - val_loss: 3.6344\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Number of emotion categories\n",
    "num_classes = 7\n",
    "\n",
    "# Build the model\n",
    "basic_model = models.Sequential([\n",
    "    # Input is 48×48 grayscale\n",
    "    layers.Input(shape=(48, 48, 1)),\n",
    "\n",
    "    # === The one convolutional layer ===\n",
    "    layers.Conv2D(\n",
    "        filters=32,            # number of feature maps\n",
    "        kernel_size=(3, 3),    # 3×3 receptive field\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    ),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten and feed into a small MLP head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with a standard optimizer + loss for multiclass classification\n",
    "basic_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Inspect the model\n",
    "basic_model.summary()\n",
    "\n",
    "# Train it\n",
    "history_basic = basic_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe3c743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18432</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,424</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18432\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,359,424\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,360,647</span> (9.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,360,647\u001b[0m (9.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,360,647</span> (9.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,360,647\u001b[0m (9.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 - 49s - 122ms/step - accuracy: 0.3520 - loss: 1.6551 - val_accuracy: 0.4117 - val_loss: 1.5370\n",
      "Epoch 2/100\n",
      "404/404 - 48s - 118ms/step - accuracy: 0.4486 - loss: 1.4526 - val_accuracy: 0.4441 - val_loss: 1.4612\n",
      "Epoch 3/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.4950 - loss: 1.3389 - val_accuracy: 0.4556 - val_loss: 1.4471\n",
      "Epoch 4/100\n",
      "404/404 - 44s - 110ms/step - accuracy: 0.5270 - loss: 1.2527 - val_accuracy: 0.4643 - val_loss: 1.4213\n",
      "Epoch 5/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.5622 - loss: 1.1735 - val_accuracy: 0.4653 - val_loss: 1.4267\n",
      "Epoch 6/100\n",
      "404/404 - 47s - 115ms/step - accuracy: 0.5945 - loss: 1.0914 - val_accuracy: 0.4674 - val_loss: 1.4792\n",
      "Epoch 7/100\n",
      "404/404 - 47s - 117ms/step - accuracy: 0.6319 - loss: 1.0041 - val_accuracy: 0.4608 - val_loss: 1.4919\n",
      "Epoch 8/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.6645 - loss: 0.9258 - val_accuracy: 0.4706 - val_loss: 1.5109\n",
      "Epoch 9/100\n",
      "404/404 - 45s - 112ms/step - accuracy: 0.7009 - loss: 0.8355 - val_accuracy: 0.4706 - val_loss: 1.5630\n",
      "Epoch 10/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.7360 - loss: 0.7506 - val_accuracy: 0.4650 - val_loss: 1.6262\n",
      "Epoch 11/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.7714 - loss: 0.6632 - val_accuracy: 0.4713 - val_loss: 1.7119\n",
      "Epoch 12/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.8048 - loss: 0.5805 - val_accuracy: 0.4556 - val_loss: 1.8410\n",
      "Epoch 13/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.8341 - loss: 0.5029 - val_accuracy: 0.4514 - val_loss: 1.9243\n",
      "Epoch 14/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.8630 - loss: 0.4255 - val_accuracy: 0.4674 - val_loss: 2.0834\n",
      "Epoch 15/100\n",
      "404/404 - 43s - 107ms/step - accuracy: 0.8925 - loss: 0.3545 - val_accuracy: 0.4723 - val_loss: 2.1914\n",
      "Epoch 16/100\n",
      "404/404 - 43s - 106ms/step - accuracy: 0.9140 - loss: 0.2959 - val_accuracy: 0.4664 - val_loss: 2.3478\n",
      "Epoch 17/100\n",
      "404/404 - 43s - 106ms/step - accuracy: 0.9319 - loss: 0.2478 - val_accuracy: 0.4577 - val_loss: 2.4676\n",
      "Epoch 18/100\n",
      "404/404 - 43s - 106ms/step - accuracy: 0.9444 - loss: 0.2102 - val_accuracy: 0.4619 - val_loss: 2.6339\n",
      "Epoch 19/100\n",
      "404/404 - 44s - 108ms/step - accuracy: 0.9563 - loss: 0.1728 - val_accuracy: 0.4598 - val_loss: 2.7635\n",
      "Epoch 20/100\n",
      "404/404 - 43s - 106ms/step - accuracy: 0.9669 - loss: 0.1379 - val_accuracy: 0.4427 - val_loss: 3.0730\n",
      "Epoch 21/100\n",
      "404/404 - 44s - 108ms/step - accuracy: 0.9746 - loss: 0.1171 - val_accuracy: 0.4559 - val_loss: 3.0288\n",
      "Epoch 22/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9752 - loss: 0.1100 - val_accuracy: 0.4483 - val_loss: 3.2286\n",
      "Epoch 23/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9810 - loss: 0.0895 - val_accuracy: 0.4486 - val_loss: 3.2733\n",
      "Epoch 24/100\n",
      "404/404 - 44s - 108ms/step - accuracy: 0.9811 - loss: 0.0882 - val_accuracy: 0.4542 - val_loss: 3.3517\n",
      "Epoch 25/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.9834 - loss: 0.0781 - val_accuracy: 0.4629 - val_loss: 3.5231\n",
      "Epoch 26/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9819 - loss: 0.0789 - val_accuracy: 0.4601 - val_loss: 3.6286\n",
      "Epoch 27/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9856 - loss: 0.0679 - val_accuracy: 0.4528 - val_loss: 3.8204\n",
      "Epoch 28/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9843 - loss: 0.0705 - val_accuracy: 0.4525 - val_loss: 3.9403\n",
      "Epoch 29/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.9837 - loss: 0.0688 - val_accuracy: 0.4594 - val_loss: 4.0164\n",
      "Epoch 30/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.9841 - loss: 0.0647 - val_accuracy: 0.4563 - val_loss: 4.1069\n",
      "Epoch 31/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9885 - loss: 0.0519 - val_accuracy: 0.4504 - val_loss: 4.0995\n",
      "Epoch 32/100\n",
      "404/404 - 45s - 110ms/step - accuracy: 0.9869 - loss: 0.0559 - val_accuracy: 0.4462 - val_loss: 4.1905\n",
      "Epoch 33/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9899 - loss: 0.0464 - val_accuracy: 0.4507 - val_loss: 4.4070\n",
      "Epoch 34/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9868 - loss: 0.0573 - val_accuracy: 0.4563 - val_loss: 4.3462\n",
      "Epoch 35/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.9808 - loss: 0.0661 - val_accuracy: 0.4549 - val_loss: 4.5074\n",
      "Epoch 36/100\n",
      "404/404 - 44s - 109ms/step - accuracy: 0.9873 - loss: 0.0534 - val_accuracy: 0.4552 - val_loss: 4.4133\n",
      "Epoch 37/100\n",
      "404/404 - 47s - 117ms/step - accuracy: 0.9902 - loss: 0.0414 - val_accuracy: 0.4580 - val_loss: 4.5595\n",
      "Epoch 38/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9918 - loss: 0.0396 - val_accuracy: 0.4441 - val_loss: 4.7365\n",
      "Epoch 39/100\n",
      "404/404 - 45s - 112ms/step - accuracy: 0.9913 - loss: 0.0403 - val_accuracy: 0.4674 - val_loss: 4.6438\n",
      "Epoch 40/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9906 - loss: 0.0417 - val_accuracy: 0.4542 - val_loss: 4.8222\n",
      "Epoch 41/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9885 - loss: 0.0471 - val_accuracy: 0.4538 - val_loss: 4.8465\n",
      "Epoch 42/100\n",
      "404/404 - 48s - 119ms/step - accuracy: 0.9862 - loss: 0.0506 - val_accuracy: 0.4605 - val_loss: 4.8082\n",
      "Epoch 43/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9875 - loss: 0.0455 - val_accuracy: 0.4403 - val_loss: 5.0179\n",
      "Epoch 44/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.9897 - loss: 0.0442 - val_accuracy: 0.4580 - val_loss: 4.9383\n",
      "Epoch 45/100\n",
      "404/404 - 39s - 95ms/step - accuracy: 0.9849 - loss: 0.0551 - val_accuracy: 0.4594 - val_loss: 5.0367\n",
      "Epoch 46/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9908 - loss: 0.0363 - val_accuracy: 0.4619 - val_loss: 5.0870\n",
      "Epoch 47/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.9924 - loss: 0.0346 - val_accuracy: 0.4511 - val_loss: 5.1940\n",
      "Epoch 48/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9939 - loss: 0.0279 - val_accuracy: 0.4532 - val_loss: 5.1065\n",
      "Epoch 49/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9913 - loss: 0.0380 - val_accuracy: 0.4528 - val_loss: 5.1341\n",
      "Epoch 50/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.9852 - loss: 0.0531 - val_accuracy: 0.4688 - val_loss: 5.1899\n",
      "Epoch 51/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.9890 - loss: 0.0398 - val_accuracy: 0.4493 - val_loss: 5.3173\n",
      "Epoch 52/100\n",
      "404/404 - 45s - 111ms/step - accuracy: 0.9924 - loss: 0.0338 - val_accuracy: 0.4612 - val_loss: 5.4044\n",
      "Epoch 53/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9883 - loss: 0.0433 - val_accuracy: 0.4556 - val_loss: 5.2920\n",
      "Epoch 54/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9925 - loss: 0.0336 - val_accuracy: 0.4650 - val_loss: 5.3719\n",
      "Epoch 55/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.9887 - loss: 0.0435 - val_accuracy: 0.4566 - val_loss: 5.5127\n",
      "Epoch 56/100\n",
      "404/404 - 45s - 112ms/step - accuracy: 0.9870 - loss: 0.0454 - val_accuracy: 0.4636 - val_loss: 5.5052\n",
      "Epoch 57/100\n",
      "404/404 - 45s - 112ms/step - accuracy: 0.9900 - loss: 0.0345 - val_accuracy: 0.4559 - val_loss: 5.5197\n",
      "Epoch 58/100\n",
      "404/404 - 45s - 112ms/step - accuracy: 0.9942 - loss: 0.0264 - val_accuracy: 0.4570 - val_loss: 5.5498\n",
      "Epoch 59/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9905 - loss: 0.0368 - val_accuracy: 0.4542 - val_loss: 5.6887\n",
      "Epoch 60/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9888 - loss: 0.0428 - val_accuracy: 0.4615 - val_loss: 5.5539\n",
      "Epoch 61/100\n",
      "404/404 - 45s - 110ms/step - accuracy: 0.9926 - loss: 0.0312 - val_accuracy: 0.4591 - val_loss: 5.6462\n",
      "Epoch 62/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9940 - loss: 0.0291 - val_accuracy: 0.4598 - val_loss: 5.6491\n",
      "Epoch 63/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9913 - loss: 0.0351 - val_accuracy: 0.4660 - val_loss: 5.5887\n",
      "Epoch 64/100\n",
      "404/404 - 47s - 116ms/step - accuracy: 0.9926 - loss: 0.0324 - val_accuracy: 0.4563 - val_loss: 5.6037\n",
      "Epoch 65/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.9927 - loss: 0.0328 - val_accuracy: 0.4566 - val_loss: 5.7144\n",
      "Epoch 66/100\n",
      "404/404 - 46s - 113ms/step - accuracy: 0.9942 - loss: 0.0245 - val_accuracy: 0.4532 - val_loss: 5.9248\n",
      "Epoch 67/100\n",
      "404/404 - 43s - 107ms/step - accuracy: 0.9897 - loss: 0.0391 - val_accuracy: 0.4518 - val_loss: 5.9976\n",
      "Epoch 68/100\n",
      "404/404 - 43s - 106ms/step - accuracy: 0.9908 - loss: 0.0358 - val_accuracy: 0.4563 - val_loss: 5.9491\n",
      "Epoch 69/100\n",
      "404/404 - 43s - 107ms/step - accuracy: 0.9939 - loss: 0.0279 - val_accuracy: 0.4591 - val_loss: 5.8270\n",
      "Epoch 70/100\n",
      "404/404 - 43s - 107ms/step - accuracy: 0.9903 - loss: 0.0405 - val_accuracy: 0.4521 - val_loss: 6.0984\n",
      "Epoch 71/100\n",
      "404/404 - 44s - 108ms/step - accuracy: 0.9927 - loss: 0.0289 - val_accuracy: 0.4507 - val_loss: 6.0571\n",
      "Epoch 72/100\n",
      "404/404 - 44s - 108ms/step - accuracy: 0.9921 - loss: 0.0303 - val_accuracy: 0.4559 - val_loss: 6.0513\n",
      "Epoch 73/100\n",
      "404/404 - 43s - 106ms/step - accuracy: 0.9928 - loss: 0.0297 - val_accuracy: 0.4545 - val_loss: 6.0908\n",
      "Epoch 74/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.9923 - loss: 0.0334 - val_accuracy: 0.4528 - val_loss: 6.1337\n",
      "Epoch 75/100\n",
      "404/404 - 47s - 117ms/step - accuracy: 0.9886 - loss: 0.0415 - val_accuracy: 0.4608 - val_loss: 6.0173\n",
      "Epoch 76/100\n",
      "404/404 - 46s - 115ms/step - accuracy: 0.9937 - loss: 0.0256 - val_accuracy: 0.4532 - val_loss: 6.0195\n",
      "Epoch 77/100\n",
      "404/404 - 48s - 119ms/step - accuracy: 0.9937 - loss: 0.0293 - val_accuracy: 0.4448 - val_loss: 6.3865\n",
      "Epoch 78/100\n",
      "404/404 - 47s - 117ms/step - accuracy: 0.9920 - loss: 0.0286 - val_accuracy: 0.4601 - val_loss: 6.3496\n",
      "Epoch 79/100\n",
      "404/404 - 46s - 114ms/step - accuracy: 0.9943 - loss: 0.0272 - val_accuracy: 0.4514 - val_loss: 6.2694\n",
      "Epoch 80/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.9926 - loss: 0.0310 - val_accuracy: 0.4612 - val_loss: 6.1526\n",
      "Epoch 81/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.9904 - loss: 0.0360 - val_accuracy: 0.4472 - val_loss: 6.2957\n",
      "Epoch 82/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.9926 - loss: 0.0304 - val_accuracy: 0.4692 - val_loss: 6.3098\n",
      "Epoch 83/100\n",
      "404/404 - 37s - 91ms/step - accuracy: 0.9924 - loss: 0.0295 - val_accuracy: 0.4608 - val_loss: 6.3428\n",
      "Epoch 84/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9942 - loss: 0.0248 - val_accuracy: 0.4580 - val_loss: 6.4307\n",
      "Epoch 85/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.9941 - loss: 0.0267 - val_accuracy: 0.4601 - val_loss: 6.6560\n",
      "Epoch 86/100\n",
      "404/404 - 34s - 85ms/step - accuracy: 0.9944 - loss: 0.0262 - val_accuracy: 0.4511 - val_loss: 6.4061\n",
      "Epoch 87/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9943 - loss: 0.0263 - val_accuracy: 0.4563 - val_loss: 6.5295\n",
      "Epoch 88/100\n",
      "404/404 - 36s - 89ms/step - accuracy: 0.9928 - loss: 0.0305 - val_accuracy: 0.4528 - val_loss: 6.4310\n",
      "Epoch 89/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.9956 - loss: 0.0252 - val_accuracy: 0.4594 - val_loss: 6.4977\n",
      "Epoch 90/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9925 - loss: 0.0316 - val_accuracy: 0.4497 - val_loss: 6.3676\n",
      "Epoch 91/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9943 - loss: 0.0239 - val_accuracy: 0.4580 - val_loss: 6.4695\n",
      "Epoch 92/100\n",
      "404/404 - 35s - 88ms/step - accuracy: 0.9933 - loss: 0.0283 - val_accuracy: 0.4483 - val_loss: 6.7240\n",
      "Epoch 93/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9925 - loss: 0.0303 - val_accuracy: 0.4521 - val_loss: 6.6249\n",
      "Epoch 94/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.9946 - loss: 0.0245 - val_accuracy: 0.4660 - val_loss: 6.4133\n",
      "Epoch 95/100\n",
      "404/404 - 36s - 88ms/step - accuracy: 0.9950 - loss: 0.0224 - val_accuracy: 0.4608 - val_loss: 6.4534\n",
      "Epoch 96/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.9933 - loss: 0.0288 - val_accuracy: 0.4511 - val_loss: 6.7468\n",
      "Epoch 97/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9932 - loss: 0.0301 - val_accuracy: 0.4497 - val_loss: 6.4113\n",
      "Epoch 98/100\n",
      "404/404 - 35s - 87ms/step - accuracy: 0.9940 - loss: 0.0281 - val_accuracy: 0.4525 - val_loss: 6.6126\n",
      "Epoch 99/100\n",
      "404/404 - 35s - 86ms/step - accuracy: 0.9914 - loss: 0.0336 - val_accuracy: 0.4584 - val_loss: 6.7631\n",
      "Epoch 100/100\n",
      "404/404 - 36s - 90ms/step - accuracy: 0.9941 - loss: 0.0244 - val_accuracy: 0.4566 - val_loss: 6.6805\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Number of emotion categories\n",
    "num_classes = 7\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    # Input is 48×48 grayscale\n",
    "    layers.Input(shape=(48, 48, 1)),\n",
    "\n",
    "    # === The one convolutional layer ===\n",
    "    layers.Conv2D(\n",
    "        filters=32,            # number of feature maps\n",
    "        kernel_size=(3, 3),    # 3×3 receptive field\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    ),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten and feed into a small MLP head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with a standard optimizer + loss for multiclass classification\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Inspect the model\n",
    "model.summary()\n",
    "\n",
    "# Train it\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    verbose=2\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
